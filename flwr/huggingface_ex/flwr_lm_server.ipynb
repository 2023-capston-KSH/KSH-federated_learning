{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "import logger\n",
    "import flwr as fl\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgWithModel(fl.server.strategy.FedAvg):\n",
    "\tdef __init__(self, model, save_path, *args, **kwargs):\n",
    "\t\tsuper().__init__(*args, **kwargs)\n",
    "\t\tself.model = model\n",
    "\t\tself.save_path = save_path\n",
    "\n",
    "\tdef aggregate_evaluate(\n",
    "\t\tself,\n",
    "\t\tserver_round: int,\n",
    "\t\tresults: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "\t\tfailures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "\t) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "\t\t\"\"\"Aggregate evaluation accuracy using weighted average.\"\"\"\n",
    "\n",
    "\t\tif not results:\n",
    "\t\t\treturn None, {}\n",
    "\n",
    "\t\t# Call aggregate_evaluate from base class (FedAvg) to aggregate loss and metrics\n",
    "\t\taggregated_loss, aggregated_metrics = super().aggregate_evaluate(server_round, results, failures)\n",
    "\n",
    "\t\t# Weigh accuracy of each client by number of examples used\n",
    "\t\taccuracies = [r.metrics[\"accuracy\"] * r.num_examples for _, r in results]\n",
    "\t\texamples = [r.num_examples for _, r in results]\n",
    "\n",
    "\t\t# Aggregate and print custom metric\n",
    "\t\taggregated_accuracy = sum(accuracies) / sum(examples)\n",
    "\t\tprint(f\"Round {server_round} accuracy aggregated from client results: {aggregated_accuracy}\")\n",
    "\n",
    "\t\t# Return aggregated loss and metrics (i.e., aggregated accuracy)\n",
    "\t\treturn aggregated_loss, {\"accuracy\": aggregated_accuracy}\n",
    "\n",
    "\tdef aggregate_fit(\n",
    "\t\tself,\n",
    "\t\tserver_round: int,\n",
    "\t\tresults: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
    "\t\tfailures: List[Union[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes], BaseException]],\n",
    "\t) -> Tuple[Optional[fl.common.Parameters], Dict[str, fl.common.Scalar]]:\n",
    "\t\t\"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "\n",
    "\t\t# Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
    "\t\taggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n",
    "\n",
    "\t\tif aggregated_parameters is not None:\n",
    "\t\t\tprint(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "\n",
    "\t\t\t# Convert `Parameters` to `List[np.ndarray]`\n",
    "\t\t\taggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
    "\n",
    "\t\t\t# Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
    "\t\t\tparams_dict = zip(self.model.state_dict().keys(), aggregated_ndarrays)\n",
    "\t\t\tstate_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "\t\t\tself.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\t\t\t# Save the model in SafeTensors format\n",
    "\t\t\tself.model.save_pretrained(f\"{self.save_path}/round_{server_round}\", safe=True)\n",
    "\t\treturn aggregated_parameters, aggregated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-12-03 16:56:28,460 | app.py:163 | Starting Flower server, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "INFO flwr 2023-12-03 16:56:28,460 | app.py:163 | Starting Flower server, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "INFO flwr 2023-12-03 16:56:28,496 | app.py:176 | Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
      "INFO flwr 2023-12-03 16:56:28,496 | app.py:176 | Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
      "INFO flwr 2023-12-03 16:56:28,497 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2023-12-03 16:56:28,497 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2023-12-03 16:56:28,498 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2023-12-03 16:56:28,498 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2023-12-03 16:57:05,321 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2023-12-03 16:57:05,321 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2023-12-03 16:57:05,323 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2023-12-03 16:57:05,323 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2023-12-03 16:57:05,324 | server.py:104 | FL starting\n",
      "INFO flwr 2023-12-03 16:57:05,324 | server.py:104 | FL starting\n",
      "DEBUG flwr 2023-12-03 16:57:06,861 | server.py:222 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
      "DEBUG flwr 2023-12-03 16:57:06,861 | server.py:222 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
      "DEBUG flwr 2023-12-03 17:46:26,764 | server.py:236 | fit_round 1 received 2 results and 0 failures\n",
      "DEBUG flwr 2023-12-03 17:46:26,764 | server.py:236 | fit_round 1 received 2 results and 0 failures\n",
      "WARNING flwr 2023-12-03 17:46:27,432 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "WARNING flwr 2023-12-03 17:46:27,432 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-12-03 17:46:27,434 | server.py:173 | evaluate_round 1: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 17:46:27,434 | server.py:173 | evaluate_round 1: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 17:46:41,951 | server.py:187 | evaluate_round 1 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-12-03 17:46:41,951 | server.py:187 | evaluate_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2023-12-03 17:46:41,953 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "WARNING flwr 2023-12-03 17:46:41,953 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-12-03 17:46:41,953 | server.py:222 | fit_round 2: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 17:46:41,953 | server.py:222 | fit_round 2: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 18:36:31,332 | server.py:236 | fit_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-12-03 18:36:31,332 | server.py:236 | fit_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-12-03 18:36:32,196 | server.py:173 | evaluate_round 2: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 18:36:32,196 | server.py:173 | evaluate_round 2: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 18:36:46,462 | server.py:187 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-12-03 18:36:46,462 | server.py:187 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-12-03 18:36:46,464 | server.py:222 | fit_round 3: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 18:36:46,464 | server.py:222 | fit_round 3: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 19:26:49,160 | server.py:236 | fit_round 3 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-12-03 19:26:49,160 | server.py:236 | fit_round 3 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-12-03 19:26:49,988 | server.py:173 | evaluate_round 3: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 19:26:49,988 | server.py:173 | evaluate_round 3: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2023-12-03 19:27:04,628 | server.py:187 | evaluate_round 3 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-12-03 19:27:04,628 | server.py:187 | evaluate_round 3 received 3 results and 0 failures\n",
      "INFO flwr 2023-12-03 19:27:04,630 | server.py:153 | FL finished in 8999.305617594975\n",
      "INFO flwr 2023-12-03 19:27:04,630 | server.py:153 | FL finished in 8999.305617594975\n",
      "INFO flwr 2023-12-03 19:27:04,663 | app.py:226 | app_fit: losses_distributed [(1, 4.365115014493489), (2, 4.478074505413008), (3, 4.46090363198044)]\n",
      "INFO flwr 2023-12-03 19:27:04,663 | app.py:226 | app_fit: losses_distributed [(1, 4.365115014493489), (2, 4.478074505413008), (3, 4.46090363198044)]\n",
      "INFO flwr 2023-12-03 19:27:04,664 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2023-12-03 19:27:04,664 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2023-12-03 19:27:04,665 | app.py:228 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2023-12-03 19:27:04,665 | app.py:228 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2023-12-03 19:27:04,665 | app.py:229 | app_fit: losses_centralized []\n",
      "INFO flwr 2023-12-03 19:27:04,665 | app.py:229 | app_fit: losses_centralized []\n",
      "INFO flwr 2023-12-03 19:27:04,666 | app.py:230 | app_fit: metrics_centralized {}\n",
      "INFO flwr 2023-12-03 19:27:04,666 | app.py:230 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 4.365115014493489\n",
       "\tround 2: 4.478074505413008\n",
       "\tround 3: 4.46090363198044"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.configure(\"1234\", filename=f\"./server.log\")\n",
    "\n",
    "fl.server.start_server(\n",
    "    server_address=\"0.0.0.0:8080\",\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=fl.server.strategy.FedAvg(),\n",
    "    grpc_max_message_length=1024 * 1024 * 1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Fine-tune a language model",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
